{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:44:58.624471Z",
     "start_time": "2020-02-17T14:44:52.107883Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>available</th>\n",
       "      <th>hello</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   available  hello  won\n",
       "0          0      1    0\n",
       "1          1      0    0\n",
       "2          0      0    1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stop_words\n",
    "\n",
    "class NLP():\n",
    "    \"\"\"\n",
    "    A NLP class to perform count_vectorizer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vocab = None\n",
    "    \n",
    "    def count_vectorizer(self, text, train = True, stop_word=None, view=False):\n",
    "        \"\"\"\n",
    "            TODO:\n",
    "                * Better preprocessing using regex, remove numbers.\n",
    "            Inputs:\n",
    "                text: Input data as list of Text.\n",
    "                stop_words: List or array of stop words. If none, default used.\n",
    "\n",
    "            Outputs:\n",
    "                Dataframe of count_vector\n",
    "\n",
    "            Steps:\n",
    "                * Lowercase applied\n",
    "                * Punctuation removed\n",
    "                * Removed stop words\n",
    "                * Performed bag of words\n",
    "                * Frequency of words\n",
    "                * Dataframe of frequency of words\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        lower_case_documents = []\n",
    "        documents=text\n",
    "        for i in documents:\n",
    "            lower_case_documents.append(i.lower())\n",
    "        \n",
    "        if view:\n",
    "            print('Step: Applying Lower Case.... Done\\n')\n",
    "    #     print(lower_case_documents)\n",
    "        sans_punctuation_documents = []\n",
    "        \n",
    "        import string\n",
    "\n",
    "        for i in lower_case_documents:\n",
    "            punctuation = string.punctuation\n",
    "\n",
    "            k = \"\"\n",
    "            for j in i:\n",
    "                if j not in punctuation:\n",
    "                    k+=j\n",
    "                    \n",
    "            sans_punctuation_documents.append(k)\n",
    "        \n",
    "        if view:\n",
    "            print('Step: Removed Punctuation....\\n')\n",
    "    #     print(sans_punctuation_documents)\n",
    "        \n",
    "        if stop_word == None:\n",
    "            stop_word = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "        \n",
    "        preprocessed_documents = []\n",
    "        for i in sans_punctuation_documents:\n",
    "            sentence = []\n",
    "            for word in i.split():\n",
    "                if word not in stop_word:\n",
    "                    sentence.append(word)\n",
    "            preprocessed_documents.append(sentence)\n",
    "        \n",
    "        if train != True:\n",
    "            return preprocessed_documents\n",
    "        \n",
    "        if view:\n",
    "            print('Step: Bag of Words... Done\\n')\n",
    "    #     print(preprocessed_documents)\n",
    "\n",
    "        frequency_list = []\n",
    "        from collections import Counter\n",
    "\n",
    "        for i in preprocessed_documents:\n",
    "            frequency_list.append(dict(Counter(i)))\n",
    "        \n",
    "        if view:\n",
    "            print('Step: Frequency of words... Done\\n')\n",
    "        \n",
    "        # often called as vocabulary\n",
    "        all_words = list(set([j for i in preprocessed_documents for j in i]))\n",
    "\n",
    "        for doc in frequency_list:\n",
    "            for word in all_words:\n",
    "                if word not in list(doc.keys()):\n",
    "                    doc[word] = 0\n",
    "        df = pd.DataFrame(frequency_list)\n",
    "        df = df[sorted(list(df.columns))]\n",
    "        \n",
    "        self.vocab = df.columns.to_list()\n",
    "        \n",
    "        if view:\n",
    "            print('Step: Count vectorizer... Done\\n')\n",
    "#         print(df.head())\n",
    "        return df\n",
    "\n",
    "nlp = NLP()\n",
    "documents = ['hello there', 'I will be available there', 'and again we won']\n",
    "count_vector = nlp.count_vectorizer(documents)\n",
    "count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:45:01.097263Z",
     "start_time": "2020-02-17T14:45:01.059267Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "df = pd.read_table('naive_bayes_tutorial/smsspamcollection/SMSSpamCollection', names=['label', 'sms_message'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:45:06.453149Z",
     "start_time": "2020-02-17T14:45:06.439161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['label'] = np.array(df['label']=='spam', dtype=np.int32)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:45:21.621078Z",
     "start_time": "2020-02-17T14:45:14.645204Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:45:21.746004Z",
     "start_time": "2020-02-17T14:45:21.627072Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>apparently</th>\n",
       "      <th>ask</th>\n",
       "      <th>buy</th>\n",
       "      <th>card</th>\n",
       "      <th>come</th>\n",
       "      <th>da</th>\n",
       "      <th>dear</th>\n",
       "      <th>forgot</th>\n",
       "      <th>going</th>\n",
       "      <th>...</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>u</th>\n",
       "      <th>wan</th>\n",
       "      <th>want</th>\n",
       "      <th>wat</th>\n",
       "      <th>welp</th>\n",
       "      <th>write</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>ü</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2  apparently  ask  buy  card  come  da  dear  forgot  going  ...  tuesday  \\\n",
       "0  0           0    0    0     0     0   0     0       0      0  ...        0   \n",
       "1  0           0    0    0     0     0   0     0       0      1  ...        0   \n",
       "2  0           1    0    0     0     0   0     0       0      0  ...        0   \n",
       "3  0           0    0    0     0     0   0     0       0      0  ...        0   \n",
       "4  2           0    1    0     1     0   1     0       1      0  ...        0   \n",
       "5  1           0    0    0     0     1   0     0       0      0  ...        0   \n",
       "6  4           0    0    1     0     0   0     0       0      0  ...        1   \n",
       "7  0           0    0    0     0     0   0     1       0      0  ...        0   \n",
       "8  0           0    0    0     0     0   0     0       0      0  ...        0   \n",
       "9  0           0    0    0     0     0   0     0       0      0  ...        0   \n",
       "\n",
       "   u  wan  want  wat  welp  write  yep  yes  ü  \n",
       "0  0    0     0    0     0      0    1    0  0  \n",
       "1  0    0     0    0     0      0    0    1  0  \n",
       "2  0    0     0    0     1      0    0    0  0  \n",
       "3  0    0     0    0     0      0    0    0  0  \n",
       "4  0    0     1    0     0      1    0    0  2  \n",
       "5  1    1     0    1     0      0    0    0  0  \n",
       "6  0    0     1    0     0      0    0    0  0  \n",
       "7  0    0     0    0     0      0    0    0  0  \n",
       "8  0    0     0    0     0      0    0    0  0  \n",
       "9  0    0     0    0     0      0    0    0  0  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.count_vectorizer(list(X_test[:10]))\n",
    "# list(X_test[:100])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T07:39:31.935550Z",
     "start_time": "2020-02-08T07:39:31.823618Z"
    }
   },
   "source": [
    "\n",
    "prob_class = dict(Counter(y_test[:50]))\n",
    "len_data = len(y_test[:50])\n",
    "prob_class = {key: round(value / len_data, 5) for key, value in prob_class.items()}\n",
    "\n",
    "prob_class\n",
    "x = nlp.count_vectorizer(list(X_test[:50]))\n",
    "y = y_test[:50]\n",
    "\n",
    "yl = y.to_list()\n",
    "data = x.copy()\n",
    "data['out'] = yl\n",
    "classes = set(yl)\n",
    "\n",
    "# prob_word = {}\n",
    "prob_word = {}\n",
    "count = x.sum(axis=0)\n",
    "total = sum(count)\n",
    "\n",
    "for word, c in zip(x.columns, count):\n",
    "    prob_word[word] = round(c / total, 5)\n",
    "\n",
    "word_class = data.groupby(by='out', axis=0).sum()\n",
    "\n",
    "total = word_class.sum(axis=1)\n",
    "\n",
    "\n",
    "# this is the probability of word being on the class. ex. p(word/class)\n",
    "data = x.copy()\n",
    "data['out'] = yl\n",
    "\n",
    "word_class = data.groupby(by='out', axis=0).sum()\n",
    "total = word_class.sum(axis=1)\n",
    "\n",
    "d = word_class.copy()\n",
    "word_class_prob = round(d.divide(total, axis=0), 5)\n",
    "word_class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:45:24.206300Z",
     "start_time": "2020-02-17T14:45:23.907170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borrow</th>\n",
       "      <th>boy</th>\n",
       "      <th>buddy</th>\n",
       "      <th>easy</th>\n",
       "      <th>game</th>\n",
       "      <th>good</th>\n",
       "      <th>hello</th>\n",
       "      <th>hi</th>\n",
       "      <th>moneey</th>\n",
       "      <th>money</th>\n",
       "      <th>replying</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     borrow    boy  buddy   easy   game   good  hello     hi  moneey  money  \\\n",
       "out                                                                           \n",
       "0     0.000  0.000  0.000  0.125  0.000  0.000  0.000  0.000   0.125  0.250   \n",
       "1     0.125  0.125  0.125  0.125  0.125  0.125  0.125  0.125   0.000  0.125   \n",
       "\n",
       "     replying   win  \n",
       "out                  \n",
       "0       0.125  0.25  \n",
       "1       0.000  0.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = ['win money now', 'easy moneey now', 'win the money by replying']\n",
    "ham = ['can you borrow money', 'good boy', 'it was easy game', 'hello buddy', 'hi']\n",
    "# spam = ['money', \"easy\", 'money']\n",
    "# ham = [\"money\", \"easy\", ]\n",
    "all_txt = spam + ham\n",
    "\n",
    "bow = nlp.count_vectorizer(all_txt)\n",
    "classes = [0, 0, 0, 1, 1, 1, 1, 1]\n",
    "bow['out'] = classes\n",
    "bow_class = bow.groupby(by='out', axis=0)\n",
    "\n",
    "# count of each class examples\n",
    "counts = bow_class.count()\n",
    "\n",
    "# count of each word on each class\n",
    "count_words_class = bow_class.sum()\n",
    "\n",
    "# find p(word/class)\n",
    "prob_w_c = bow_class.sum() / counts\n",
    "\n",
    "# find p(class/word)\n",
    "prob_c_w = round(prob_w_c * counts / counts.sum(axis=0), 5)\n",
    "prob_c_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:45:25.178466Z",
     "start_time": "2020-02-17T14:45:25.170470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'boy', 'boy', 'need', 'money']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = ['you are good boy. boy need money?',\"boy need money?\" ]\n",
    "txt = nlp.count_vectorizer(txt, train=False)\n",
    "p = prob_c_w\n",
    "txt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:45:26.597094Z",
     "start_time": "2020-02-17T14:45:26.551122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0.140625, 1: 0.234375}, {0: 0.01171875, 1: 0.001220703125})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = ['easy boy easy. boy you need easy money?', \"it was easy game\" ]\n",
    "\n",
    "txt = nlp.count_vectorizer(txt, train= False)\n",
    "# words = txt.columns.to_list()\n",
    "words = dict(Counter(txt[0]))\n",
    "vocab = p.columns.to_list()\n",
    "\n",
    "classes = [0, 1]\n",
    "class_prob = counts / counts.sum(axis=0)\n",
    "class_prob = dict(class_prob.mean(axis=1))\n",
    "\n",
    "# probs will store denominator value for each class. We have to add all values of it to get denominator\n",
    "probs = {}\n",
    "\n",
    "# numinator\n",
    "\n",
    "num = {k:v for k,v in class_prob.items()}\n",
    "\n",
    "for w in words.keys():\n",
    "    if w in vocab:\n",
    "        for c in classes:\n",
    "            if probs.get(c) != None:\n",
    "                if p[w][c] != 0:\n",
    "                    probs[c] += p[w][c] * class_prob[c]\n",
    "                    num[c] *= p[w][c]\n",
    "            else:  \n",
    "                probs[c] = p[w][c] * class_prob[c] \n",
    "                num[c] *= p[w][c]\n",
    "\n",
    "\n",
    "probs, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:45:47.690657Z",
     "start_time": "2020-02-17T14:45:47.643682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['easy', 'boy', 'easy', 'boy', 'need', 'easy', 'money'], ['hello', 'easy', 'game']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, {0: 0.0, 1: 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = ['easy boy easy. boy you need easy money?', \"hello it was easy game\" ]\n",
    "# txt = ['Win the easy money now', 'I am missing you buddy']\n",
    "\n",
    "txt = nlp.count_vectorizer(txt, train= False)\n",
    "# words = txt.columns.to_list()\n",
    "print(txt)\n",
    "words = dict(Counter(txt[1]))\n",
    "vocab = p.columns.to_list()\n",
    "\n",
    "classes = [0, 1]\n",
    "class_prob = counts / counts.sum(axis=0)\n",
    "class_prob = dict(class_prob.mean(axis=1))\n",
    "\n",
    "# probs will store denominator value for each class. We have to add all values of it to get denominator\n",
    "# probs will store values of P(w/c) where c is classes and w is words.\n",
    "probs = {}\n",
    "\n",
    "# numinator\n",
    "# same as probs\n",
    "\n",
    "num = {k:v for k,v in class_prob.items()}\n",
    "\n",
    "for w in words.keys():\n",
    "    if w in vocab:\n",
    "        for c in classes:\n",
    "            if probs.get(c) != None:\n",
    "                if p[w][c] != 0:\n",
    "                    probs[c] *= p[w][c] \n",
    "                    num[c] *= p[w][c]\n",
    "            else:  \n",
    "                probs[c] = p[w][c] * class_prob[c] \n",
    "                num[c] *= p[w][c]\n",
    "\n",
    "# to find probability of class given word or P(c/w), we have formula\n",
    "# = p(w/c) * p(c) / p(w)\n",
    "# p(w) = sum over all p(w/c) * p(c) is TP + TN \n",
    "                \n",
    "denom = sum(probs.values())\n",
    "probs = {k: v/denom for k,v in num.items()}\n",
    "sum(probs.values()), probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:55:55.083843Z",
     "start_time": "2020-02-17T14:55:55.005334Z"
    },
    "code_folding": [
     1,
     28,
     90,
     155
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9056603773584906, 1: 0.09433962264150944}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NaiveBayes():\n",
    "    \"\"\"\n",
    "        A class to perform Naive Bayes on text.\n",
    "        Methods:\n",
    "            * fit: to train a model\n",
    "            * predict: to do prediction\n",
    "\n",
    "        Use Cases:\n",
    "        spam = ['win money now', 'easy moneey now', 'win the money by replying']\n",
    "        ham = ['can you borrow money', 'good boy', 'it was easy game', 'hello buddy', 'hi']\n",
    "\n",
    "        all_txt = spam + ham\n",
    "        classes = [0, 0, 0, 1, 1, 1, 1, 1]\n",
    "        nb = NaiveBayes(all_txt, classes)\n",
    "        nb.fit()\n",
    "\n",
    "        test = ['easy boy easy. boy you need easy money?', \"it was easy game\" ]\n",
    "        nb.predict([spam[1]])\n",
    "        # {0: 0.06976744186046512, 1: 0.9302325581395349}\n",
    "    \"\"\"\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.cond_probs = {}\n",
    "        self.features = []\n",
    "        self.classes = []\n",
    "        self.class_prob = {}\n",
    "    \n",
    "    def fit(self, view=False):\n",
    "        \"\"\"\n",
    "            Input: List of texts.\n",
    "            \n",
    "            A method to find all the probability of P(word/class).\n",
    "            It finds out the probabilty for each word to be on each class.\n",
    "            Example:\n",
    "            --------\n",
    "                spam = ['win money now', 'easy moneey now', 'win the money by replying']\n",
    "                ham = ['can you borrow money', 'good boy', 'it was easy game', 'hello buddy', 'hi']\n",
    "\n",
    "                all_txt = spam + ham\n",
    "                classes = [0, 0, 0, 1, 1, 1, 1, 1]\n",
    "                nb = NaiveBayes(all_txt, classes)\n",
    "                nb.fit()\n",
    "                \n",
    "            Steps:\n",
    "            ---------\n",
    "            * Find the BoW\n",
    "            * Find the examples on each class\n",
    "            * Find the probability of word on class p(w/c)\n",
    "            * Find the probability of class given word. P(c/w)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        text = self.text\n",
    "        label = self.label\n",
    "        \n",
    "        \n",
    "        bow = nlp.count_vectorizer(text)\n",
    "        \n",
    "        self.features = bow.columns.to_list() \n",
    "        \n",
    "        if view:\n",
    "            print('Your BoW is:\\n', bow)\n",
    "            \n",
    "        classes = label\n",
    "        \n",
    "        self.classes = list(Counter(classes).keys())\n",
    "        \n",
    "        bow['out'] = classes\n",
    "        bow_class = bow.groupby(by='out', axis=0)\n",
    "\n",
    "        # count of each class examples\n",
    "        counts = bow_class.count()\n",
    "        \n",
    "        # used for prediction\n",
    "        class_prob = counts / counts.sum(axis=0)\n",
    "        class_prob = dict(class_prob.mean(axis=1))\n",
    "        self.class_prob = class_prob\n",
    "        \n",
    "        # count of each word on each class\n",
    "        self.count_words_class = bow_class.sum()\n",
    "\n",
    "        # find prob of word in each class.... no. of that word in class / total word in class\n",
    "        prob_w_c = bow_class.sum() / counts\n",
    "        \n",
    "        # find p(word/class)\n",
    "        \n",
    "        prob_w_c = round(prob_w_c * counts / counts.sum(axis=0), 5)\n",
    "        self.cond_probs = prob_w_c\n",
    "        \n",
    "    def classes_(self):\n",
    "        \"\"\"\n",
    "        A method to see all classes counts for each word.\n",
    "        \"\"\"\n",
    "        return self.count_words_class \n",
    "    \n",
    "    def predict(self, example):\n",
    "        \"\"\"\n",
    "            A method for prediction.\n",
    "            Input: List of text. \n",
    "            Output: Prediction for each classes.\n",
    "            \n",
    "            Example:\n",
    "            ----------\n",
    "            \n",
    "            >>>test = ['easy boy easy. boy you need easy money?', \"it was easy game\" ]\n",
    "            >>>nb.predict([spam[1]])\n",
    "            {0: 0.06976744186046512, 1: 0.9302325581395349}\n",
    "        \"\"\"\n",
    "        txt = nlp.count_vectorizer(example, train= False)\n",
    "        words = dict(Counter(txt[0]))\n",
    "        \n",
    "        vocab = self.features\n",
    "        classes = self.classes\n",
    "        class_prob = self.class_prob\n",
    "        p = self.cond_probs\n",
    "        \n",
    "        # probs will store denominator value for each class. We have to add all values of it to get denominator\n",
    "        # probs will store values of P(w/c) where c is classes and w is words.\n",
    "        probs = {}\n",
    "\n",
    "        # numinator\n",
    "        # same as probs\n",
    "\n",
    "        num = {k:v for k,v in class_prob.items()}\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        c, ~c\n",
    "        p(~c/w1, w2, w3) = p(w1, w2, w3 / ~c) * p(~c) / (p(w1, w2, w3/c) * p(c) + p(w1, w2, w3/~c) * p(~c))\n",
    "        \n",
    "        \n",
    "        p(c/ w1, w1, w3) = p(w1, w2, w3 / c) * p(c) / (p(w1, w2, w3/c) * p(c) + p(w1 , w2, w3 / ~c) * p(~c))\n",
    "        p(w1, w2, w3/c) = p(w1/c) * p(w2/c) * p(w3/c) = p(w1 and w2 and w3 / c)\n",
    "        \"\"\"\n",
    "        \n",
    "        for w in words.keys():\n",
    "            if w in vocab:\n",
    "                for c in classes:\n",
    "                    if probs.get(c) != None:\n",
    "                        if p[w][c] != 0:\n",
    "                            probs[c] *= p[w][c] \n",
    "                            num[c] *= p[w][c]\n",
    "                    else:  \n",
    "                        probs[c] = p[w][c] * class_prob[c] \n",
    "                        num[c] *= p[w][c]\n",
    "\n",
    "        # to find probability of class given word or P(c/w), we have formula\n",
    "        # = p(w/c) * p(c) / p(w)\n",
    "        # p(w) = sum over all p(w/c) * p(c) is TP + TN \n",
    "\n",
    "        denom = sum(probs.values())\n",
    "        probs = {k: v/denom for k,v in num.items()}\n",
    "        return probs\n",
    "\n",
    "        \"\"\"     \n",
    "            ### scarp code\n",
    "                #         sum(probs.values()), probs\n",
    "                #         example = nlp.count_vectorizer(example)\n",
    "                #         words = example.columns.to_list()\n",
    "\n",
    "                #         vocab = self.features\n",
    "                #         classes = self.classes\n",
    "                #         p = self.cond_probs\n",
    "\n",
    "                #         probs = {}\n",
    "\n",
    "                #         class_prob = self.class_prob\n",
    "\n",
    "                #         for w in words:\n",
    "                #             if w in vocab:\n",
    "                #                 for c in classes:\n",
    "                #                     if probs.get(c) != None:\n",
    "                #                         # this is actually p(class/word) * p(class)\n",
    "                #                         probs[c] *= p[w][c]\n",
    "                #                     else:\n",
    "                #                         probs[c] = p[w][c] * class_prob[c]\n",
    "\n",
    "                #         return probs\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "spam = ['win money now', 'easy moneey now', 'win the money by replying']\n",
    "ham = ['can you borrow money', 'good boy', 'it was easy game', 'hello buddy', 'hi']\n",
    "\n",
    "all_txt = spam + ham\n",
    "classes = [0, 0, 0, 1, 1, 1, 1, 1]\n",
    "nb = NaiveBayes(all_txt, classes)\n",
    "nb.fit()\n",
    "\n",
    "# nb.cond_probs\n",
    "test = ['easy boy easy. boy you need easy money?', \"buddy, easy money\", 'win easy money by replying']\n",
    "nb.predict([test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:55:55.409988Z",
     "start_time": "2020-02-17T14:55:55.401987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['win money now',\n",
       " 'easy moneey now',\n",
       " 'win the money by replying',\n",
       " 'can you borrow money',\n",
       " 'good boy',\n",
       " 'it was easy game',\n",
       " 'hello buddy',\n",
       " 'hi']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T14:55:56.188212Z",
     "start_time": "2020-02-17T14:55:56.179199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 0.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### prediction\n",
    "pred = []\n",
    "test = ['Win the easy money now', 'I am missing you buddy']\n",
    "test = ['easy boy easy. boy you need easy money?', \"it was easy game\" ]\n",
    "\n",
    "nb.predict([spam[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T15:00:20.546736Z",
     "start_time": "2020-02-17T15:00:20.491770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9056603773584906, 1: 0.09433962264150944}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from naive_bayes import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(all_txt, classes)\n",
    "nb.fit()\n",
    "\n",
    "# nb.cond_probs\n",
    "test = ['easy boy easy. boy you need easy money?', \"buddy, easy money\", 'win easy money by replying']\n",
    "nb.predict([test[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T14:22:30.941478Z",
     "start_time": "2020-02-09T14:22:30.806273Z"
    }
   },
   "source": [
    "\\begin{equation}\\label{eq:}\n",
    "P(s/w1, w2, w3....wn) = \\frac{P(w1, w2.....wn/s) * P(s)}{P(w1, w2, w3...wn)}\\\\\n",
    "P(w1, w2.....wn/s) = P(w1/s) * P(w2/s) ...P(wn/s)\\\\\n",
    "\\therefore P(s/w1, w2, w3....wn) = \\frac{P(s) * P(w1/s) * P(w2/s) ...P(wn/s)} {P(s) * P(w1/s) * P(w2/s) ...P(wn/s) + P(h) * P(w1/h) * P(w2/~h) ...P(wn/h)} \\\\\n",
    "or \\frac{P(s)*\\prod_{i=1}^{n}{P(w_i/s)}} {\\sum_{c=s, h}{P(c)*\\prod_{i=1}^{n}{P(w_i/c)}}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{P(s)*\\prod_{i=1}^{n}{P(w_i/s)}} {\\sum_{c=s, h}{P(c)*\\prod_{i=1}^{n}{P(w_i/c)}}}\n",
    "\\end{equation}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
